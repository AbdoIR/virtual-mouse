{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028877dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "class HandDetector:\n",
    "    def __init__(self, mode=False, max_hands=1, detection_confidence=0.7, tracking_confidence=0.5):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=mode,\n",
    "            max_num_hands=max_hands,\n",
    "            min_detection_confidence=detection_confidence,\n",
    "            min_tracking_confidence=tracking_confidence\n",
    "        )\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "    def find_hands(self, img, draw=True):\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(img_rgb)\n",
    "        if self.results.multi_hand_landmarks and draw:\n",
    "            for hand_landmarks in self.results.multi_hand_landmarks:\n",
    "                self.mp_draw.draw_landmarks(img, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "    def get_landmark_positions(self, img, hand_num=0):\n",
    "        landmarks = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            hand = self.results.multi_hand_landmarks[hand_num]\n",
    "            for id, lm in enumerate(hand.landmark):\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                landmarks.append((id, cx, cy))\n",
    "        return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3856064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual Mouse Started! Controls:\n",
      "- Index finger up: Move cursor\n",
      "- Index + Middle close: Left click\n",
      "- Thumb + Index close: Right click\n",
      "- Pinch (Thumb + Index) and move: Drag\n",
      "\n",
      "Keyboard Controls:\n",
      "- 't': Toggle always on top\n",
      "- 's': Toggle small/large window\n",
      "- 'l': Toggle hand landmarks\n",
      "- 'q': Quit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "class VirtualMouse:\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.detector = HandDetector(max_hands=1)\n",
    "        self.screen_w, self.screen_h = pyautogui.size()\n",
    "        \n",
    "        # Get camera dimensions\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.cam_w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.cam_h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Movement area (avoid edges for better control)\n",
    "        self.frame_reduction = 100\n",
    "        \n",
    "        # Smoothing parameters\n",
    "        self.smoothening = 5\n",
    "        self.prev_x, self.prev_y = 0, 0\n",
    "        self.curr_x, self.curr_y = 0, 0\n",
    "        \n",
    "        # Control parameters\n",
    "        self.movement_threshold = 5  # Lower threshold for better responsiveness\n",
    "        self.click_distance = 40  # Distance between fingers for click\n",
    "        self.drag_distance = 35   # Distance for drag gesture\n",
    "        \n",
    "        # State management\n",
    "        self.is_dragging = False\n",
    "        self.last_click_time = 0\n",
    "        self.click_cooldown = 0.3\n",
    "        \n",
    "        # Position history for smoothing\n",
    "        self.position_history = []\n",
    "        self.history_length = 3\n",
    "        \n",
    "        # Gesture state tracking\n",
    "        self.gesture_state = \"NONE\"\n",
    "        self.gesture_frames = 0\n",
    "        self.gesture_threshold = 3  # Frames to confirm gesture\n",
    "        \n",
    "        # GUI control variables\n",
    "        self.always_on_top = True\n",
    "        self.window_size_small = False\n",
    "        self.show_landmarks = True\n",
    "        \n",
    "        # Disable PyAutoGUI fail-safe\n",
    "        pyautogui.FAILSAFE = False\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Virtual Mouse Started! Controls:\")\n",
    "        print(\"- Index finger up: Move cursor\")\n",
    "        print(\"- Index + Middle close: Left click\")\n",
    "        print(\"- Thumb + Index close: Right click\")\n",
    "        print(\"- Pinch (Thumb + Index) and move: Drag\")\n",
    "        print(\"\\nKeyboard Controls:\")\n",
    "        print(\"- 't': Toggle always on top\")\n",
    "        print(\"- 's': Toggle small/large window\")\n",
    "        print(\"- 'l': Toggle hand landmarks\")\n",
    "        print(\"- 'q': Quit\")\n",
    "        \n",
    "        # Create window with specific properties\n",
    "        window_name = \"AI Virtual Mouse\"\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        # Set initial window properties\n",
    "        self._update_window_properties(window_name)\n",
    "        \n",
    "        while True:\n",
    "            success, img = self.cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            img = cv2.flip(img, 1)\n",
    "            h, w, c = img.shape\n",
    "            \n",
    "            # Draw control area\n",
    "            cv2.rectangle(img, (self.frame_reduction, self.frame_reduction), \n",
    "                         (w - self.frame_reduction, h - self.frame_reduction), (255, 0, 255), 2)\n",
    "            \n",
    "            # Find hands and draw landmarks based on setting\n",
    "            img = self.detector.find_hands(img, draw=self.show_landmarks)\n",
    "            landmarks = self.detector.get_landmark_positions(img)\n",
    "\n",
    "            if landmarks:\n",
    "                # Get finger positions\n",
    "                x1, y1 = landmarks[8][1], landmarks[8][2]  # Index finger tip\n",
    "                x2, y2 = landmarks[12][1], landmarks[12][2]  # Middle finger tip\n",
    "                x4, y4 = landmarks[4][1], landmarks[4][2]   # Thumb tip\n",
    "                \n",
    "                # Always draw finger points for visual feedback\n",
    "                cv2.circle(img, (x1, y1), 8, (255, 0, 0), cv2.FILLED)  # Index - Blue\n",
    "                cv2.circle(img, (x2, y2), 8, (0, 255, 0), cv2.FILLED)  # Middle - Green\n",
    "                cv2.circle(img, (x4, y4), 8, (0, 0, 255), cv2.FILLED)  # Thumb - Red\n",
    "\n",
    "                # Check finger states\n",
    "                fingers_up = self._check_fingers_up(landmarks)\n",
    "                \n",
    "                # Calculate distances\n",
    "                index_middle_dist = np.hypot(x2 - x1, y2 - y1)\n",
    "                thumb_index_dist = np.hypot(x4 - x1, y4 - y1)\n",
    "                \n",
    "                # Gesture detection and action\n",
    "                current_gesture = self._detect_gesture(fingers_up, index_middle_dist, thumb_index_dist)\n",
    "                \n",
    "                # Gesture state management with frame counting for stability\n",
    "                if current_gesture == self.gesture_state:\n",
    "                    self.gesture_frames += 1\n",
    "                else:\n",
    "                    self.gesture_frames = 0\n",
    "                    self.gesture_state = current_gesture\n",
    "                \n",
    "                # Execute actions based on confirmed gestures\n",
    "                if self.gesture_frames >= self.gesture_threshold:\n",
    "                    self._execute_gesture_action(current_gesture, x1, y1, x4, y4, img)\n",
    "                \n",
    "                # Display current gesture\n",
    "                cv2.putText(img, f\"Gesture: {self.gesture_state}\", (20, 50), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                # Display distances for debugging\n",
    "                cv2.putText(img, f\"IM: {int(index_middle_dist)}\", (20, 80), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                cv2.putText(img, f\"TI: {int(thumb_index_dist)}\", (150, 80), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Display status and controls\n",
    "            self._draw_status_info(img, h, w)\n",
    "\n",
    "            cv2.imshow(window_name, img)\n",
    "            \n",
    "            # Handle keyboard input\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('t'):\n",
    "                self.always_on_top = not self.always_on_top\n",
    "                self._update_window_properties(window_name)\n",
    "                print(f\"Always on top: {'ON' if self.always_on_top else 'OFF'}\")\n",
    "            elif key == ord('s'):\n",
    "                self.window_size_small = not self.window_size_small\n",
    "                self._update_window_properties(window_name)\n",
    "                print(f\"Window size: {'SMALL' if self.window_size_small else 'LARGE'}\")\n",
    "            elif key == ord('l'):\n",
    "                self.show_landmarks = not self.show_landmarks\n",
    "                print(f\"Hand landmarks: {'ON' if self.show_landmarks else 'OFF'}\")\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def _update_window_properties(self, window_name):\n",
    "        \"\"\"Update window properties based on current settings\"\"\"\n",
    "        try:\n",
    "            # Set window to stay on top or not\n",
    "            if self.always_on_top:\n",
    "                cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)\n",
    "            else:\n",
    "                cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 0)\n",
    "            \n",
    "            # Set window size\n",
    "            if self.window_size_small:\n",
    "                cv2.resizeWindow(window_name, 400, 300)\n",
    "                # Position window in top-right corner\n",
    "                cv2.moveWindow(window_name, self.screen_w - 420, 20)\n",
    "            else:\n",
    "                cv2.resizeWindow(window_name, 640, 480)\n",
    "                # Position window in a convenient location\n",
    "                cv2.moveWindow(window_name, 50, 50)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Note: Some window properties may not be supported on this system: {e}\")\n",
    "\n",
    "    def _draw_status_info(self, img, h, w):\n",
    "        \"\"\"Draw status information and controls on the image\"\"\"\n",
    "        # Status indicators\n",
    "        status_y = h - 120\n",
    "        \n",
    "        # Always on top status\n",
    "        top_color = (0, 255, 0) if self.always_on_top else (0, 0, 255)\n",
    "        cv2.putText(img, f\"OnTop: {'ON' if self.always_on_top else 'OFF'}\", \n",
    "                   (20, status_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, top_color, 1)\n",
    "        \n",
    "        # Window size status\n",
    "        size_color = (0, 255, 255) if self.window_size_small else (255, 255, 0)\n",
    "        cv2.putText(img, f\"Size: {'SMALL' if self.window_size_small else 'LARGE'}\", \n",
    "                   (130, status_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, size_color, 1)\n",
    "        \n",
    "        # Landmarks status\n",
    "        landmarks_color = (0, 255, 0) if self.show_landmarks else (0, 0, 255)\n",
    "        cv2.putText(img, f\"Landmarks: {'ON' if self.show_landmarks else 'OFF'}\", \n",
    "                   (250, status_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, landmarks_color, 1)\n",
    "        \n",
    "        # Control instructions (more compact)\n",
    "        instructions = [\n",
    "            \"Controls: [T]op [S]ize [L]andmarks [Q]uit\",\n",
    "        ]\n",
    "        \n",
    "        for i, instruction in enumerate(instructions):\n",
    "            cv2.putText(img, instruction, (20, h - 50 + i * 20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    def _check_fingers_up(self, landmarks):\n",
    "        \"\"\"Check which fingers are up\"\"\"\n",
    "        fingers = []\n",
    "        \n",
    "        # Thumb (check x-coordinate relative to previous joint)\n",
    "        if landmarks[4][1] > landmarks[3][1]:  # Right hand\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "        \n",
    "        # Four fingers (check y-coordinate)\n",
    "        for tip_id in [8, 12, 16, 20]:\n",
    "            if landmarks[tip_id][2] < landmarks[tip_id - 2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "        \n",
    "        return fingers\n",
    "\n",
    "    def _detect_gesture(self, fingers_up, index_middle_dist, thumb_index_dist):\n",
    "        \"\"\"Detect current gesture based on finger positions\"\"\"\n",
    "        \n",
    "        # Only index finger up - MOVE\n",
    "        if fingers_up[1] == 1 and fingers_up[2] == 0 and fingers_up[3] == 0:\n",
    "            return \"MOVE\"\n",
    "        \n",
    "        # Index and middle up, close together - LEFT CLICK\n",
    "        elif (fingers_up[1] == 1 and fingers_up[2] == 1 and \n",
    "              index_middle_dist < self.click_distance):\n",
    "            return \"LEFT_CLICK\"\n",
    "        \n",
    "        # Thumb and index close together - RIGHT CLICK or DRAG\n",
    "        elif thumb_index_dist < self.drag_distance:\n",
    "            if fingers_up[0] == 1 and fingers_up[1] == 1:\n",
    "                return \"DRAG\"\n",
    "            else:\n",
    "                return \"RIGHT_CLICK\"\n",
    "        \n",
    "        return \"NONE\"\n",
    "\n",
    "    def _execute_gesture_action(self, gesture, x1, y1, x4, y4, img):\n",
    "        \"\"\"Execute action based on detected gesture\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if gesture == \"MOVE\":\n",
    "            self._handle_cursor_movement(x1, y1)\n",
    "            cv2.putText(img, \"MOVING\", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "        elif gesture == \"LEFT_CLICK\":\n",
    "            if (current_time - self.last_click_time) > self.click_cooldown:\n",
    "                pyautogui.click()\n",
    "                self.last_click_time = current_time\n",
    "                cv2.putText(img, \"LEFT CLICK\", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "        elif gesture == \"RIGHT_CLICK\":\n",
    "            if (current_time - self.last_click_time) > self.click_cooldown:\n",
    "                pyautogui.rightClick()\n",
    "                self.last_click_time = current_time\n",
    "                cv2.putText(img, \"RIGHT CLICK\", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                \n",
    "        elif gesture == \"DRAG\":\n",
    "            if not self.is_dragging:\n",
    "                pyautogui.mouseDown()\n",
    "                self.is_dragging = True\n",
    "                cv2.putText(img, \"DRAG START\", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            \n",
    "            # Use midpoint of thumb and index for drag movement\n",
    "            drag_x = (x1 + x4) // 2\n",
    "            drag_y = (y1 + y4) // 2\n",
    "            self._handle_cursor_movement(drag_x, drag_y)\n",
    "            cv2.putText(img, \"DRAGGING\", (20, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            \n",
    "        else:  # \"NONE\"\n",
    "            if self.is_dragging:\n",
    "                pyautogui.mouseUp()\n",
    "                self.is_dragging = False\n",
    "                cv2.putText(img, \"DRAG END\", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    def _handle_cursor_movement(self, x, y):\n",
    "        \"\"\"Handle smooth cursor movement with improved mapping\"\"\"\n",
    "        \n",
    "        # Only move if finger is within the control area\n",
    "        if (x < self.frame_reduction or x > self.cam_w - self.frame_reduction or\n",
    "            y < self.frame_reduction or y > self.cam_h - self.frame_reduction):\n",
    "            return\n",
    "        \n",
    "        # Map camera coordinates to screen coordinates\n",
    "        # Improved mapping that maintains aspect ratio and provides better control\n",
    "        x3 = np.interp(x, (self.frame_reduction, self.cam_w - self.frame_reduction), (0, self.screen_w))\n",
    "        y3 = np.interp(y, (self.frame_reduction, self.cam_h - self.frame_reduction), (0, self.screen_h))\n",
    "        \n",
    "        # Store position history for smoothing\n",
    "        self.position_history.append((x3, y3))\n",
    "        if len(self.position_history) > self.history_length:\n",
    "            self.position_history.pop(0)\n",
    "        \n",
    "        # Calculate smoothed position\n",
    "        if len(self.position_history) > 0:\n",
    "            avg_x = sum(pos[0] for pos in self.position_history) / len(self.position_history)\n",
    "            avg_y = sum(pos[1] for pos in self.position_history) / len(self.position_history)\n",
    "        else:\n",
    "            avg_x, avg_y = x3, y3\n",
    "        \n",
    "        # Calculate movement distance\n",
    "        if self.prev_x != 0 or self.prev_y != 0:\n",
    "            distance = np.hypot(avg_x - self.prev_x, avg_y - self.prev_y)\n",
    "            \n",
    "            # Only move if beyond threshold to avoid jitter\n",
    "            if distance > self.movement_threshold:\n",
    "                # Apply smoothing\n",
    "                self.curr_x = self.prev_x + (avg_x - self.prev_x) / self.smoothening\n",
    "                self.curr_y = self.prev_y + (avg_y - self.prev_y) / self.smoothening\n",
    "                \n",
    "                # Move cursor (no need to flip x-coordinate as camera is already flipped)\n",
    "                pyautogui.moveTo(self.curr_x, self.curr_y)\n",
    "                self.prev_x, self.prev_y = self.curr_x, self.curr_y\n",
    "        else:\n",
    "            # First movement\n",
    "            self.prev_x, self.prev_y = avg_x, avg_y\n",
    "            self.curr_x, self.curr_y = avg_x, avg_y\n",
    "            pyautogui.moveTo(self.curr_x, self.curr_y)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vm = VirtualMouse()\n",
    "    vm.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
